app_name: "rcv1"
parameter_name: "rcv1_w"
linear_method {

training_data {
format: TEXT
text: LIBSVM
file: "/home/parameter_server/dat/part.*"
}

local_cache {
format: BIN
file: "/tmp/rcv1/"
}

model_output {
format: TEXT
file: "/home/parameter_server/output/rcv1_batch_l1lr"
}

loss {
type: LOGIT
}

# lambda * |w|_1
penalty {
type: L1
lambda: 1
}

learning_rate {
type: CONSTANT
eta: 1
}

solver {
# turn it off to elimiate the randomness, but may affects the convergence rate
random_feature_block_order : true
# block-coordinate updating. We divide a feature group into feature_block_ratio
# x nnz_feature_per_instance blocks. If = 0, then use all features
feature_block_ratio : 4
# max number pass of traing data
max_pass_of_data : 20
# bounded-delay consistency
max_block_delay : 0
# convergance critiria. stop if the relative objective <= epsilon
epsilon : 1e-4
# features which occurs <= *tail_feature_count* will be filtered before training
tail_feature_freq : 0
}

darling {
# decrease these numbers for harder dataset
delta_init_value : 5
delta_max_value : 10
# increasing this number reduces the effect of kkt filter.
kkt_filter_threshold_ratio : 100
}

}
